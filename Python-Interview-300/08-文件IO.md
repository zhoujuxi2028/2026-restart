# 08 - 文件IO（15题）

## 难度分布
- 简单：8题
- 中等：5题
- 困难：2题

---

## 第166题：文件的打开和关闭

**问题**：文件操作的基本方法

**答案**：
```python
# 基本打开方式
f = open('file.txt', 'r')
content = f.read()
f.close()

# 使用with语句（推荐）
with open('file.txt', 'r') as f:
    content = f.read()
# 自动关闭文件

# 打开模式
'r'   # 只读（默认）
'w'   # 写入（覆盖）
'a'   # 追加
'x'   # 独占创建（文件存在则失败）
'b'   # 二进制模式
't'   # 文本模式（默认）
'+'   # 读写模式

# 常用组合
'rb'  # 二进制只读
'wb'  # 二进制写入
'r+'  # 读写
'w+'  # 读写（覆盖）
'a+'  # 读写（追加）

# 指定编码
with open('file.txt', 'r', encoding='utf-8') as f:
    content = f.read()

# 处理不同编码
with open('file.txt', 'r', encoding='gbk') as f:
    content = f.read()

# 错误处理
try:
    with open('file.txt', 'r', encoding='utf-8') as f:
        content = f.read()
except FileNotFoundError:
    print("文件不存在")
except PermissionError:
    print("没有权限")
except UnicodeDecodeError:
    print("编码错误")
```

---

## 第167题：读取文件

**问题**：各种文件读取方法

**答案**：
```python
# read() - 读取全部内容
with open('file.txt', 'r') as f:
    content = f.read()
    print(content)

# read(size) - 读取指定字节数
with open('file.txt', 'r') as f:
    chunk = f.read(100)  # 读取100字节

# readline() - 读取一行
with open('file.txt', 'r') as f:
    line = f.readline()
    print(line)

# readlines() - 读取所有行到列表
with open('file.txt', 'r') as f:
    lines = f.readlines()
    for line in lines:
        print(line.strip())

# 迭代文件对象（推荐，内存高效）
with open('file.txt', 'r') as f:
    for line in f:
        print(line.strip())

# 读取大文件（按块读取）
def read_in_chunks(file_path, chunk_size=1024):
    with open(file_path, 'r') as f:
        while True:
            chunk = f.read(chunk_size)
            if not chunk:
                break
            yield chunk

for chunk in read_in_chunks('large_file.txt'):
    process(chunk)

# 读取二进制文件
with open('image.jpg', 'rb') as f:
    binary_data = f.read()

# 使用seek和tell
with open('file.txt', 'r') as f:
    print(f.tell())  # 当前位置：0
    f.read(10)
    print(f.tell())  # 当前位置：10
    f.seek(0)        # 回到开头
    print(f.tell())  # 当前位置：0

# 读取最后几行
def tail(file_path, n=10):
    with open(file_path, 'r') as f:
        return f.readlines()[-n:]

# 逐行处理大文件
def process_large_file(file_path):
    with open(file_path, 'r') as f:
        for line_num, line in enumerate(f, 1):
            if line_num % 1000 == 0:
                print(f"处理第{line_num}行")
            # 处理行内容
            process_line(line)
```

---

## 第168题：写入文件

**问题**：各种文件写入方法

**答案**：
```python
# write() - 写入字符串
with open('file.txt', 'w') as f:
    f.write('Hello, World!\n')

# writelines() - 写入字符串列表
lines = ['第一行\n', '第二行\n', '第三行\n']
with open('file.txt', 'w') as f:
    f.writelines(lines)

# 追加模式
with open('file.txt', 'a') as f:
    f.write('追加内容\n')

# 写入多行
with open('file.txt', 'w') as f:
    f.write('第一行\n')
    f.write('第二行\n')
    f.write('第三行\n')

# 使用print写入
with open('file.txt', 'w') as f:
    print('Hello, World!', file=f)
    print('Second line', file=f)

# 写入二进制文件
data = b'\x00\x01\x02\x03'
with open('file.bin', 'wb') as f:
    f.write(data)

# 安全写入（先写临时文件）
import os
import tempfile

def safe_write(file_path, content):
    # 写入临时文件
    fd, temp_path = tempfile.mkstemp()
    try:
        with os.fdopen(fd, 'w') as f:
            f.write(content)
        # 替换原文件
        os.replace(temp_path, file_path)
    except:
        os.unlink(temp_path)
        raise

# 缓冲写入
with open('file.txt', 'w', buffering=8192) as f:
    for i in range(1000):
        f.write(f'Line {i}\n')

# 立即刷新缓冲区
with open('file.txt', 'w') as f:
    f.write('Important data')
    f.flush()  # 立即写入磁盘

# 格式化写入
data = {'name': 'Alice', 'age': 25, 'city': 'NYC'}
with open('output.txt', 'w') as f:
    for key, value in data.items():
        f.write(f'{key}: {value}\n')
```

---

## 第169题：文件位置操作

**问题**：seek和tell的使用

**答案**：
```python
# tell() - 获取当前位置
with open('file.txt', 'r') as f:
    print(f.tell())  # 0
    f.read(10)
    print(f.tell())  # 10

# seek() - 移动到指定位置
with open('file.txt', 'r') as f:
    f.seek(10)       # 移动到第10个字节
    content = f.read()

# seek的第二个参数
with open('file.txt', 'r') as f:
    f.seek(0, 0)     # 从文件开头偏移（默认）
    f.seek(10, 0)    # 从开头偏移10字节

    f.seek(0, 1)     # 从当前位置偏移
    f.seek(5, 1)     # 从当前位置向后5字节

    f.seek(0, 2)     # 从文件末尾偏移
    f.seek(-10, 2)   # 从末尾向前10字节

# 获取文件大小
with open('file.txt', 'r') as f:
    f.seek(0, 2)     # 移到末尾
    size = f.tell()
    print(f'文件大小: {size}字节')

# 读取文件中间部分
def read_middle(file_path, start, length):
    with open(file_path, 'r') as f:
        f.seek(start)
        return f.read(length)

# 反向读取文件
def read_reverse(file_path):
    with open(file_path, 'rb') as f:
        f.seek(0, 2)  # 移到末尾
        size = f.tell()

        lines = []
        buffer = b''

        for pos in range(size - 1, -1, -1):
            f.seek(pos)
            char = f.read(1)

            if char == b'\n':
                lines.append(buffer[::-1].decode())
                buffer = b''
            else:
                buffer += char

        if buffer:
            lines.append(buffer[::-1].decode())

        return lines

# 二进制文件的精确定位
with open('data.bin', 'rb') as f:
    # 读取文件头
    header = f.read(100)

    # 跳过一段数据
    f.seek(1000, 1)

    # 读取特定位置的数据
    f.seek(5000)
    data = f.read(100)
```

---

## 第170题：文件和目录操作

**问题**：使用os和shutil模块

**答案**：
```python
import os
import shutil

# 检查文件/目录是否存在
if os.path.exists('file.txt'):
    print('文件存在')

if os.path.isfile('file.txt'):
    print('是文件')

if os.path.isdir('folder'):
    print('是目录')

# 获取文件信息
print(os.path.getsize('file.txt'))  # 文件大小
print(os.path.getmtime('file.txt'))  # 修改时间
print(os.path.getctime('file.txt'))  # 创建时间
print(os.path.getatime('file.txt'))  # 访问时间

# 路径操作
print(os.path.basename('/path/to/file.txt'))  # file.txt
print(os.path.dirname('/path/to/file.txt'))   # /path/to
print(os.path.split('/path/to/file.txt'))     # ('/path/to', 'file.txt')
print(os.path.splitext('file.txt'))           # ('file', '.txt')

# 连接路径
path = os.path.join('folder', 'subfolder', 'file.txt')

# 绝对路径和相对路径
print(os.path.abspath('file.txt'))
print(os.path.realpath('link.txt'))  # 解析符号链接

# 创建目录
os.mkdir('new_folder')               # 创建单个目录
os.makedirs('path/to/folder')        # 创建多级目录

# 删除文件和目录
os.remove('file.txt')                # 删除文件
os.rmdir('empty_folder')             # 删除空目录
shutil.rmtree('folder')              # 删除目录树

# 重命名和移动
os.rename('old.txt', 'new.txt')
shutil.move('file.txt', 'folder/')

# 复制文件
shutil.copy('source.txt', 'dest.txt')        # 复制文件
shutil.copy2('source.txt', 'dest.txt')       # 复制文件和元数据
shutil.copytree('src_folder', 'dst_folder')  # 复制目录树

# 列出目录内容
files = os.listdir('.')
for file in files:
    print(file)

# 遍历目录树
for root, dirs, files in os.walk('.'):
    print(f'目录: {root}')
    for file in files:
        print(f'  文件: {file}')

# 使用glob匹配文件
import glob

# 查找所有txt文件
txt_files = glob.glob('*.txt')

# 递归查找
all_py_files = glob.glob('**/*.py', recursive=True)

# 使用pathlib（Python 3.4+）
from pathlib import Path

# 创建Path对象
p = Path('file.txt')

# 检查存在
if p.exists():
    print('存在')

# 读写文件
content = p.read_text()
p.write_text('new content')

# 路径操作
print(p.name)        # file.txt
print(p.stem)        # file
print(p.suffix)      # .txt
print(p.parent)      # .

# 遍历目录
for item in Path('.').iterdir():
    if item.is_file():
        print(f'文件: {item}')
```

---

## 第171题：CSV文件操作

**问题**：读写CSV文件

**答案**：
```python
import csv

# 读取CSV
with open('data.csv', 'r', encoding='utf-8') as f:
    reader = csv.reader(f)
    for row in reader:
        print(row)

# 读取为字典
with open('data.csv', 'r', encoding='utf-8') as f:
    reader = csv.DictReader(f)
    for row in reader:
        print(row['name'], row['age'])

# 写入CSV
data = [
    ['姓名', '年龄', '城市'],
    ['Alice', '25', 'NYC'],
    ['Bob', '30', 'LA']
]

with open('output.csv', 'w', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerows(data)

# 写入单行
with open('output.csv', 'a', newline='', encoding='utf-8') as f:
    writer = csv.writer(f)
    writer.writerow(['Charlie', '35', 'Chicago'])

# 写入字典
data = [
    {'name': 'Alice', 'age': 25, 'city': 'NYC'},
    {'name': 'Bob', 'age': 30, 'city': 'LA'}
]

with open('output.csv', 'w', newline='', encoding='utf-8') as f:
    fieldnames = ['name', 'age', 'city']
    writer = csv.DictWriter(f, fieldnames=fieldnames)

    writer.writeheader()
    writer.writerows(data)

# 自定义分隔符
with open('data.tsv', 'r') as f:
    reader = csv.reader(f, delimiter='\t')
    for row in reader:
        print(row)

# 处理引号
with open('data.csv', 'w', newline='') as f:
    writer = csv.writer(f, quoting=csv.QUOTE_ALL)
    writer.writerow(['name', 'description'])
    writer.writerow(['Alice', 'She said, "Hello"'])

# 使用pandas（更强大）
import pandas as pd

# 读取CSV
df = pd.read_csv('data.csv')
print(df.head())

# 写入CSV
df.to_csv('output.csv', index=False)

# 选择特定列
df = pd.read_csv('data.csv', usecols=['name', 'age'])

# 跳过行
df = pd.read_csv('data.csv', skiprows=1)

# 处理缺失值
df = pd.read_csv('data.csv', na_values=['NA', 'null'])
```

---

## 第172题：JSON文件操作

**问题**：读写JSON文件

**答案**：
```python
import json

# 读取JSON
with open('data.json', 'r', encoding='utf-8') as f:
    data = json.load(f)
    print(data)

# 写入JSON
data = {
    'name': 'Alice',
    'age': 25,
    'hobbies': ['reading', 'coding'],
    'address': {
        'city': 'NYC',
        'country': 'USA'
    }
}

with open('output.json', 'w', encoding='utf-8') as f:
    json.dump(data, f, indent=2, ensure_ascii=False)

# JSON字符串转换
json_str = json.dumps(data, indent=2, ensure_ascii=False)
print(json_str)

data = json.loads(json_str)
print(data)

# 美化输出
with open('output.json', 'w', encoding='utf-8') as f:
    json.dump(data, f, indent=4, ensure_ascii=False, sort_keys=True)

# 处理特殊类型
from datetime import datetime

class DateEncoder(json.JSONEncoder):
    def default(self, obj):
        if isinstance(obj, datetime):
            return obj.isoformat()
        return super().default(obj)

data = {
    'name': 'Alice',
    'created_at': datetime.now()
}

with open('output.json', 'w') as f:
    json.dump(data, f, cls=DateEncoder)

# 自定义解码
def custom_decoder(dct):
    if 'created_at' in dct:
        dct['created_at'] = datetime.fromisoformat(dct['created_at'])
    return dct

with open('data.json', 'r') as f:
    data = json.load(f, object_hook=custom_decoder)

# 处理大型JSON文件
import ijson

with open('large.json', 'r') as f:
    # 迭代处理
    for item in ijson.items(f, 'item'):
        process(item)

# JSON Lines格式
# 每行一个JSON对象
def read_jsonl(file_path):
    with open(file_path, 'r') as f:
        for line in f:
            yield json.loads(line)

def write_jsonl(file_path, data):
    with open(file_path, 'w') as f:
        for item in data:
            f.write(json.dumps(item, ensure_ascii=False) + '\n')

# 实际应用：配置文件
class Config:
    def __init__(self, file_path):
        self.file_path = file_path
        self.data = self.load()

    def load(self):
        try:
            with open(self.file_path, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            return {}

    def save(self):
        with open(self.file_path, 'w') as f:
            json.dump(self.data, f, indent=2)

    def get(self, key, default=None):
        return self.data.get(key, default)

    def set(self, key, value):
        self.data[key] = value
        self.save()
```

---

## 第173题：二进制文件操作

**问题**：读写二进制文件

**答案**：
```python
# 读取二进制文件
with open('image.jpg', 'rb') as f:
    data = f.read()
    print(f'文件大小: {len(data)}字节')

# 写入二进制文件
data = b'\x00\x01\x02\x03\x04\x05'
with open('output.bin', 'wb') as f:
    f.write(data)

# 使用struct处理二进制数据
import struct

# 打包数据
data = struct.pack('i', 12345)  # 整数
data = struct.pack('f', 3.14)   # 浮点数
data = struct.pack('3s', b'abc')  # 字符串

# 解包数据
value = struct.unpack('i', data)[0]

# 复杂结构
# 格式: 整数, 浮点数, 5字节字符串
data = struct.pack('if5s', 42, 3.14, b'hello')

with open('data.bin', 'wb') as f:
    f.write(data)

with open('data.bin', 'rb') as f:
    data = f.read()
    num, float_val, string = struct.unpack('if5s', data)

# 读取特定字节
with open('file.bin', 'rb') as f:
    # 读取前100字节
    header = f.read(100)

    # 逐字节读取
    while True:
        byte = f.read(1)
        if not byte:
            break
        print(hex(ord(byte)))

# 使用bytearray
data = bytearray(b'Hello')
data[0] = ord('h')  # 修改
data.append(ord('!'))  # 追加
print(bytes(data))

# 内存映射文件（大文件）
import mmap

with open('large_file.bin', 'r+b') as f:
    # 映射到内存
    mmapped = mmap.mmap(f.fileno(), 0)

    # 像字符串一样访问
    print(mmapped[0:10])

    # 查找
    index = mmapped.find(b'pattern')

    # 修改
    mmapped[0:5] = b'Hello'

    mmapped.close()

# 图片处理
from PIL import Image
import io

# 读取图片
with open('image.jpg', 'rb') as f:
    img_data = f.read()
    img = Image.open(io.BytesIO(img_data))
    print(img.size)

# 保存图片
img.save('output.jpg')

# 二进制文件复制
def copy_binary(src, dst, chunk_size=8192):
    with open(src, 'rb') as fsrc:
        with open(dst, 'wb') as fdst:
            while True:
                chunk = fsrc.read(chunk_size)
                if not chunk:
                    break
                fdst.write(chunk)
```

---

## 第174题：文件压缩和解压

**问题**：使用zipfile和tarfile

**答案**：
```python
import zipfile
import tarfile
import gzip
import shutil

# ZIP文件操作
# 创建ZIP
with zipfile.ZipFile('archive.zip', 'w') as zipf:
    zipf.write('file1.txt')
    zipf.write('file2.txt')
    zipf.write('folder/file3.txt')

# 添加到现有ZIP
with zipfile.ZipFile('archive.zip', 'a') as zipf:
    zipf.write('file4.txt')

# 读取ZIP
with zipfile.ZipFile('archive.zip', 'r') as zipf:
    # 列出文件
    print(zipf.namelist())

    # 获取文件信息
    for info in zipf.infolist():
        print(f'{info.filename}: {info.file_size}字节')

    # 读取文件内容
    content = zipf.read('file1.txt')

    # 解压所有文件
    zipf.extractall('extract_folder')

    # 解压单个文件
    zipf.extract('file1.txt', 'output_folder')

# 压缩整个目录
def zip_directory(folder_path, output_path):
    with zipfile.ZipFile(output_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
        for root, dirs, files in os.walk(folder_path):
            for file in files:
                file_path = os.path.join(root, file)
                arcname = os.path.relpath(file_path, folder_path)
                zipf.write(file_path, arcname)

# TAR文件操作
# 创建tar
with tarfile.open('archive.tar', 'w') as tar:
    tar.add('file1.txt')
    tar.add('folder')

# 创建tar.gz
with tarfile.open('archive.tar.gz', 'w:gz') as tar:
    tar.add('folder')

# 创建tar.bz2
with tarfile.open('archive.tar.bz2', 'w:bz2') as tar:
    tar.add('folder')

# 读取tar
with tarfile.open('archive.tar.gz', 'r:gz') as tar:
    # 列出文件
    print(tar.getnames())

    # 解压
    tar.extractall('extract_folder')

    # 解压单个文件
    tar.extract('file1.txt')

# GZIP文件操作
# 压缩文件
with open('file.txt', 'rb') as f_in:
    with gzip.open('file.txt.gz', 'wb') as f_out:
        shutil.copyfileobj(f_in, f_out)

# 解压文件
with gzip.open('file.txt.gz', 'rb') as f_in:
    with open('file.txt', 'wb') as f_out:
        shutil.copyfileobj(f_in, f_out)

# 直接读写gzip文件
import gzip

with gzip.open('file.txt.gz', 'wt', encoding='utf-8') as f:
    f.write('Hello, World!\n')

with gzip.open('file.txt.gz', 'rt', encoding='utf-8') as f:
    content = f.read()

# 使用shutil进行压缩
shutil.make_archive('archive', 'zip', 'folder')
shutil.make_archive('archive', 'gztar', 'folder')
shutil.make_archive('archive', 'bztar', 'folder')

# 解压
shutil.unpack_archive('archive.zip', 'extract_folder')
```

---

## 第175题：临时文件和目录

**问题**：使用tempfile模块

**答案**：
```python
import tempfile
import os

# 临时文件
# 自动删除的临时文件
with tempfile.TemporaryFile(mode='w+') as f:
    f.write('temporary data')
    f.seek(0)
    print(f.read())
# 文件自动删除

# 命名的临时文件
with tempfile.NamedTemporaryFile(mode='w+', delete=False) as f:
    print(f'临时文件: {f.name}')
    f.write('data')
    temp_path = f.name

# 手动删除
os.unlink(temp_path)

# 临时目录
with tempfile.TemporaryDirectory() as tmpdir:
    print(f'临时目录: {tmpdir}')

    # 在临时目录中创建文件
    file_path = os.path.join(tmpdir, 'test.txt')
    with open(file_path, 'w') as f:
        f.write('test')
# 目录自动删除

# 获取临时目录路径
temp_dir = tempfile.gettempdir()
print(f'系统临时目录: {temp_dir}')

# 创建临时文件名
temp_name = tempfile.mktemp()  # 不推荐，不安全

# 安全的方式
fd, temp_path = tempfile.mkstemp()
try:
    with os.fdopen(fd, 'w') as f:
        f.write('data')
    # 使用临时文件
    process(temp_path)
finally:
    os.unlink(temp_path)

# 临时文件用于缓存
class Cache:
    def __init__(self):
        self.tmpdir = tempfile.mkdtemp()

    def save(self, key, data):
        file_path = os.path.join(self.tmpdir, key)
        with open(file_path, 'w') as f:
            f.write(data)

    def load(self, key):
        file_path = os.path.join(self.tmpdir, key)
        with open(file_path, 'r') as f:
            return f.read()

    def cleanup(self):
        shutil.rmtree(self.tmpdir)

# 实际应用：安全的文件写入
def safe_write(file_path, content):
    # 先写到临时文件
    fd, temp_path = tempfile.mkstemp(dir=os.path.dirname(file_path))
    try:
        with os.fdopen(fd, 'w') as f:
            f.write(content)
        # 原子替换
        os.replace(temp_path, file_path)
    except:
        os.unlink(temp_path)
        raise
```

---

## 第176题：文件锁定

**问题**：实现文件锁定机制

**答案**：
```python
import fcntl  # Unix/Linux
import time

# Unix/Linux文件锁
def lock_file(f):
    fcntl.flock(f.fileno(), fcntl.LOCK_EX)

def unlock_file(f):
    fcntl.flock(f.fileno(), fcntl.LOCK_UN)

# 使用示例
with open('shared_file.txt', 'r+') as f:
    try:
        lock_file(f)
        # 执行文件操作
        content = f.read()
        f.write('modified content')
    finally:
        unlock_file(f)

# 非阻塞锁
def try_lock_file(f):
    try:
        fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
        return True
    except IOError:
        return False

# 跨平台文件锁
import os
import sys

class FileLock:
    def __init__(self, file_path):
        self.file_path = file_path
        self.lock_file = file_path + '.lock'
        self.fd = None

    def acquire(self):
        # 创建锁文件
        while True:
            try:
                self.fd = os.open(
                    self.lock_file,
                    os.O_CREAT | os.O_EXCL | os.O_RDWR
                )
                break
            except OSError:
                time.sleep(0.1)

    def release(self):
        if self.fd:
            os.close(self.fd)
            os.remove(self.lock_file)

    def __enter__(self):
        self.acquire()
        return self

    def __exit__(self, exc_type, exc_val, exc_tb):
        self.release()

# 使用
with FileLock('data.txt'):
    # 执行文件操作
    with open('data.txt', 'r+') as f:
        content = f.read()
        f.write('modified')

# 使用第三方库：filelock
from filelock import FileLock

lock = FileLock("file.txt.lock")
with lock:
    with open("file.txt", "r") as f:
        content = f.read()

# 超时锁
with lock.acquire(timeout=10):
    # 最多等待10秒
    process_file()
```

---

## 第177题：文件监控

**问题**：监控文件系统变化

**答案**：
```python
# 使用watchdog库
from watchdog.observers import Observer
from watchdog.events import FileSystemEventHandler
import time

class FileWatcher(FileSystemEventHandler):
    def on_created(self, event):
        print(f'文件创建: {event.src_path}')

    def on_deleted(self, event):
        print(f'文件删除: {event.src_path}')

    def on_modified(self, event):
        print(f'文件修改: {event.src_path}')

    def on_moved(self, event):
        print(f'文件移动: {event.src_path} -> {event.dest_path}')

# 启动监控
observer = Observer()
observer.schedule(FileWatcher(), path='.', recursive=True)
observer.start()

try:
    while True:
        time.sleep(1)
except KeyboardInterrupt:
    observer.stop()

observer.join()

# 简单的轮询方式
import os
import time

def watch_file(file_path, callback):
    last_mtime = os.path.getmtime(file_path)

    while True:
        time.sleep(1)
        current_mtime = os.path.getmtime(file_path)

        if current_mtime != last_mtime:
            callback(file_path)
            last_mtime = current_mtime

def on_file_change(file_path):
    print(f'{file_path} 已修改')

# 监控文件大小
def watch_file_size(file_path):
    last_size = os.path.getsize(file_path)

    while True:
        time.sleep(1)
        current_size = os.path.getsize(file_path)

        if current_size > last_size:
            # 文件增长，读取新内容
            with open(file_path, 'r') as f:
                f.seek(last_size)
                new_content = f.read()
                print(new_content)
            last_size = current_size

# 实时日志监控（类似tail -f）
def tail_follow(file_path):
    with open(file_path, 'r') as f:
        # 移到文件末尾
        f.seek(0, 2)

        while True:
            line = f.readline()
            if line:
                print(line, end='')
            else:
                time.sleep(0.1)
```

---

## 第178题：配置文件处理

**问题**：读写INI和YAML配置文件

**答案**：
```python
import configparser

# INI文件
# 写入INI
config = configparser.ConfigParser()

config['DEFAULT'] = {
    'ServerAliveInterval': '45',
    'Compression': 'yes'
}

config['database'] = {
    'host': 'localhost',
    'port': '3306',
    'user': 'admin'
}

with open('config.ini', 'w') as f:
    config.write(f)

# 读取INI
config = configparser.ConfigParser()
config.read('config.ini')

print(config['database']['host'])
print(config['database'].get('port'))
print(config['database'].getint('port'))

# 检查section和option
if config.has_section('database'):
    print('database section存在')

if config.has_option('database', 'host'):
    print('host option存在')

# 修改配置
config['database']['host'] = '127.0.0.1'
config['database']['password'] = 'secret'

with open('config.ini', 'w') as f:
    config.write(f)

# YAML文件
import yaml

# 写入YAML
data = {
    'database': {
        'host': 'localhost',
        'port': 3306,
        'users': ['admin', 'user1', 'user2']
    },
    'app': {
        'debug': True,
        'secret_key': 'secret'
    }
}

with open('config.yaml', 'w') as f:
    yaml.dump(data, f, default_flow_style=False)

# 读取YAML
with open('config.yaml', 'r') as f:
    config = yaml.safe_load(f)
    print(config['database']['host'])

# 环境变量配置
import os

class Config:
    DEBUG = os.getenv('DEBUG', 'False') == 'True'
    DATABASE_URL = os.getenv('DATABASE_URL', 'sqlite:///app.db')
    SECRET_KEY = os.getenv('SECRET_KEY', 'dev-secret-key')

# .env文件
from dotenv import load_dotenv

load_dotenv()  # 加载.env文件

database_url = os.getenv('DATABASE_URL')
```

---

## 第179题：文件编码处理

**问题**：处理不同编码的文件

**答案**：
```python
# 指定编码读取
with open('file.txt', 'r', encoding='utf-8') as f:
    content = f.read()

# 常见编码
encodings = ['utf-8', 'gbk', 'gb2312', 'big5', 'ascii', 'latin-1']

# 自动检测编码
import chardet

def detect_encoding(file_path):
    with open(file_path, 'rb') as f:
        raw_data = f.read()
        result = chardet.detect(raw_data)
        return result['encoding']

encoding = detect_encoding('file.txt')
with open('file.txt', 'r', encoding=encoding) as f:
    content = f.read()

# 转换编码
def convert_encoding(input_file, output_file, from_enc, to_enc):
    with open(input_file, 'r', encoding=from_enc) as f:
        content = f.read()

    with open(output_file, 'w', encoding=to_enc) as f:
        f.write(content)

# 处理编码错误
# 忽略错误
with open('file.txt', 'r', encoding='utf-8', errors='ignore') as f:
    content = f.read()

# 替换错误字符
with open('file.txt', 'r', encoding='utf-8', errors='replace') as f:
    content = f.read()

# 使用其他字符替换
with open('file.txt', 'r', encoding='utf-8', errors='backslashreplace') as f:
    content = f.read()

# BOM处理
# UTF-8 BOM
with open('file.txt', 'r', encoding='utf-8-sig') as f:
    content = f.read()

# 检查BOM
def has_bom(file_path):
    with open(file_path, 'rb') as f:
        bom = f.read(3)
        return bom == b'\xef\xbb\xbf'

# 二进制和文本转换
text = "你好，世界"
encoded = text.encode('utf-8')  # bytes
decoded = encoded.decode('utf-8')  # str

# 处理混合编码
def read_mixed_encoding(file_path):
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            return f.read()
    except UnicodeDecodeError:
        # 尝试其他编码
        for encoding in ['gbk', 'gb2312', 'big5']:
            try:
                with open(file_path, 'r', encoding=encoding) as f:
                    return f.read()
            except UnicodeDecodeError:
                continue

        # 最后使用二进制模式
        with open(file_path, 'rb') as f:
            return f.read().decode('utf-8', errors='ignore')
```

---

## 第180题：文件IO综合实践

**问题**：构建文件处理工具

**答案**：
```python
import os
import shutil
import hashlib
from pathlib import Path
from typing import List, Iterator

class FileManager:
    """文件管理工具类"""

    @staticmethod
    def read_file(file_path: str, encoding: str = 'utf-8') -> str:
        """安全读取文件"""
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                return f.read()
        except FileNotFoundError:
            raise FileNotFoundError(f"文件不存在: {file_path}")
        except PermissionError:
            raise PermissionError(f"没有读取权限: {file_path}")

    @staticmethod
    def write_file(file_path: str, content: str, encoding: str = 'utf-8'):
        """安全写入文件"""
        # 确保目录存在
        os.makedirs(os.path.dirname(file_path), exist_ok=True)

        # 写入临时文件，然后原子替换
        temp_file = file_path + '.tmp'
        try:
            with open(temp_file, 'w', encoding=encoding) as f:
                f.write(content)
            os.replace(temp_file, file_path)
        except:
            if os.path.exists(temp_file):
                os.unlink(temp_file)
            raise

    @staticmethod
    def copy_file(src: str, dst: str, overwrite: bool = False):
        """复制文件"""
        if not overwrite and os.path.exists(dst):
            raise FileExistsError(f"目标文件已存在: {dst}")

        os.makedirs(os.path.dirname(dst), exist_ok=True)
        shutil.copy2(src, dst)

    @staticmethod
    def move_file(src: str, dst: str, overwrite: bool = False):
        """移动文件"""
        if not overwrite and os.path.exists(dst):
            raise FileExistsError(f"目标文件已存在: {dst}")

        os.makedirs(os.path.dirname(dst), exist_ok=True)
        shutil.move(src, dst)

    @staticmethod
    def delete_file(file_path: str):
        """删除文件"""
        if os.path.exists(file_path):
            os.remove(file_path)

    @staticmethod
    def get_file_hash(file_path: str, algorithm: str = 'md5') -> str:
        """计算文件哈希值"""
        hash_obj = hashlib.new(algorithm)

        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b''):
                hash_obj.update(chunk)

        return hash_obj.hexdigest()

    @staticmethod
    def find_files(directory: str, pattern: str = '*',
                   recursive: bool = True) -> List[str]:
        """查找文件"""
        path = Path(directory)
        if recursive:
            return [str(p) for p in path.rglob(pattern)]
        else:
            return [str(p) for p in path.glob(pattern)]

    @staticmethod
    def read_lines(file_path: str, encoding: str = 'utf-8') -> Iterator[str]:
        """逐行读取大文件"""
        with open(file_path, 'r', encoding=encoding) as f:
            for line in f:
                yield line.rstrip('\n\r')

    @staticmethod
    def backup_file(file_path: str, backup_dir: str = None):
        """备份文件"""
        if backup_dir is None:
            backup_dir = os.path.dirname(file_path)

        filename = os.path.basename(file_path)
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        backup_name = f"{filename}.{timestamp}.bak"
        backup_path = os.path.join(backup_dir, backup_name)

        shutil.copy2(file_path, backup_path)
        return backup_path

# 使用示例
fm = FileManager()

# 读写文件
content = fm.read_file('input.txt')
fm.write_file('output.txt', content.upper())

# 复制和移动
fm.copy_file('source.txt', 'backup/source.txt')
fm.move_file('old.txt', 'archive/old.txt')

# 计算哈希
file_hash = fm.get_file_hash('data.txt', 'sha256')

# 查找文件
py_files = fm.find_files('.', '*.py', recursive=True)

# 处理大文件
for line in fm.read_lines('large_file.txt'):
    process(line)

# 备份文件
backup_path = fm.backup_file('important.txt')
```

---

## 学习笔记

在这里记录你的学习心得和遇到的问题：

```
日期：

重点知识：
- 文件的打开模式和编码
- CSV和JSON文件处理
- 二进制文件操作
- 文件压缩和解压
- 临时文件的使用

易错点：
- 忘记关闭文件
- 编码问题
- 路径分隔符问题
- 大文件的内存问题

实践心得：
```

---

## 进度跟踪

完成题目：0/15

- [ ] 第166题
- [ ] 第167题
- [ ] 第168题
- [ ] 第169题
- [ ] 第170题
- [ ] 第171题
- [ ] 第172题
- [ ] 第173题
- [ ] 第174题
- [ ] 第175题
- [ ] 第176题
- [ ] 第177题
- [ ] 第178题
- [ ] 第179题
- [ ] 第180题
